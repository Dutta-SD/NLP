{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aggression_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjcdGfaTw7_s"
      },
      "source": [
        "# Aggression Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdaTT1q9VnC4",
        "outputId": "19f39ce8-0eb7-40c1-9285-429de6da3ffe"
      },
      "source": [
        "! pip install transformers -qqq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 7.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 41.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 28.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MSolq7cV501"
      },
      "source": [
        "def create_aug_pipeline(model_name):\n",
        "  return pipeline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPvnwMvtwff8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import metrics, ensemble, svm, feature_extraction, naive_bayes, neural_network\n",
        "import xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "peKcY1ylxE6V",
        "outputId": "935a6347-cf32-4e0a-e493-6af5d642fb92"
      },
      "source": [
        "train = pd.read_csv('https://raw.githubusercontent.com/Dutta-SD/NLP/master/Aggression_Detection/trac2_eng_train.csv')\n",
        "val = pd.read_csv('https://raw.githubusercontent.com/Dutta-SD/NLP/master/Aggression_Detection/trac2_eng_dev.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Sub-task A</th>\n",
              "      <th>Sub-task B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C45.451</td>\n",
              "      <td>Next part</td>\n",
              "      <td>NAG</td>\n",
              "      <td>NGEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C47.11</td>\n",
              "      <td>Iii8mllllllm\\nMdxfvb8o90lplppi0005</td>\n",
              "      <td>NAG</td>\n",
              "      <td>NGEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C33.79</td>\n",
              "      <td>ðŸ¤£ðŸ¤£ðŸ˜‚ðŸ˜‚ðŸ¤£ðŸ¤£ðŸ¤£ðŸ˜‚osm vedio ....keep it up...make more v...</td>\n",
              "      <td>NAG</td>\n",
              "      <td>NGEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C4.1961</td>\n",
              "      <td>What the fuck was this? I respect shwetabh and...</td>\n",
              "      <td>NAG</td>\n",
              "      <td>NGEN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C10.153</td>\n",
              "      <td>Concerned authorities should bring arundathi R...</td>\n",
              "      <td>NAG</td>\n",
              "      <td>NGEN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID  ... Sub-task B\n",
              "0  C45.451  ...       NGEN\n",
              "1   C47.11  ...       NGEN\n",
              "2   C33.79  ...       NGEN\n",
              "3  C4.1961  ...       NGEN\n",
              "4  C10.153  ...       NGEN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKYI2fp0Vhr2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjYAqvcrx1vV"
      },
      "source": [
        "def seed_all():\n",
        "  np.random.seed(0)\n",
        "  \n",
        "seed_all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cXvfvCmx5D8"
      },
      "source": [
        "def get_clean_dataset(\n",
        "    df_raw,\n",
        "    train = True,\n",
        "    task_name='A', \n",
        "    other_target = 'B',\n",
        "    target_mapping = None,\n",
        "    vectorizer=None,\n",
        "    text_cleaner=None):\n",
        "  '''\n",
        "  ===============================================================\n",
        "  get_clean_dataset - cleans the dataset, returns text and labels\n",
        "  ===============================================================\n",
        "\n",
        "  :df_raw - pandas dataframe for cleaning\n",
        "  :train - flag to see if training data sent or not\n",
        "  :task_name - the target to predict\n",
        "  :other_target - other target column, we predict only one target column at a time\n",
        "  :vectorizer - vectorizes the data\n",
        "  :text_cleaner - useful for removing punctuation, etc(function)\n",
        "  '''\n",
        "  # Compulsory\n",
        "  assert target_mapping is not None, \"NO TARGET MAPPING FOUND\"\n",
        "\n",
        "  col_str = f'Sub-task {task_name}'\n",
        "  other_col = f'Sub-task {other_target}'\n",
        "\n",
        "  if 'ID' in df_raw.columns:\n",
        "    df_raw = df_raw.drop(['ID'], axis = 1)\n",
        "\n",
        "  targets = df_raw[col_str].map(target_mapping).values\n",
        "  text = df_raw['Text'].values\n",
        "\n",
        "  if text_cleaner:\n",
        "    text = text_cleaner(text)\n",
        "\n",
        "  if vectorizer:\n",
        "    if train:\n",
        "      text = vectorizer.fit_transform(text)\n",
        "    else:\n",
        "      text = vectorizer.transform(text)\n",
        "  \n",
        "\n",
        "  return text, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMXse1OO8R6B"
      },
      "source": [
        "s = np.bincount(train[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jm-i1Mx7ERH",
        "outputId": "940847c3-3808-4ab8-ffb1-ade54ed7ddad"
      },
      "source": [
        "task_1_map ={\n",
        "    'NAG' : 0,\n",
        "    'CAG' : 1,\n",
        "    'OAG' : 2\n",
        "}\n",
        "v1 = feature_extraction.text.CountVectorizer()\n",
        "v2 = feature_extraction.text.TfidfVectorizer()\n",
        "\n",
        "train_clean = get_clean_dataset(train, True,'A','B', task_1_map, vectorizer=v2)\n",
        "val_clean = get_clean_dataset(val, False, 'A', 'B', task_1_map, vectorizer=v2)\n",
        "\n",
        "weights = {i : s.sum() / s[i] for i in range(3)}\n",
        "\n",
        "model1 = ensemble.RandomForestClassifier(class_weight=weights, random_state=0, criterion='entropy')\n",
        "model2 = svm.LinearSVC(class_weight=weights, random_state=0)\n",
        "model3 = xgboost.XGBClassifier(scale_pos_weight=weights, random_state=0)\n",
        "model4 = neural_network.MLPClassifier(random_state=0, verbose=True, learning_rate='adaptive',max_iter=5 )\n",
        "\n",
        "model_list = [model1, model2, model3, model4]\n",
        "\n",
        "print(f\"Vectorizer used : {type(v2).__name__}\", end=\"\\n\\n\")\n",
        "\n",
        "for i, model in enumerate(model_list):\n",
        "  print(f\"model no {i}, training\")\n",
        "  print(f\"model name {type(model).__name__}\")\n",
        "  preds = model.fit(train_clean[0], train_clean[1]).predict(val_clean[0])\n",
        "  true_preds = val_clean[1]\n",
        "  print(metrics.classification_report(true_preds, preds))\n",
        "  print(f\"\\nDone with model {i}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizer used : TfidfVectorizer\n",
            "\n",
            "model no 0, training\n",
            "model name RandomForestClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      1.00      0.89       836\n",
            "           1       1.00      0.01      0.02       117\n",
            "           2       0.88      0.12      0.22       113\n",
            "\n",
            "    accuracy                           0.80      1066\n",
            "   macro avg       0.89      0.38      0.37      1066\n",
            "weighted avg       0.83      0.80      0.72      1066\n",
            "\n",
            "\n",
            "Done with model 0\n",
            "model no 1, training\n",
            "model name LinearSVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       836\n",
            "           1       0.40      0.37      0.38       117\n",
            "           2       0.55      0.50      0.53       113\n",
            "\n",
            "    accuracy                           0.80      1066\n",
            "   macro avg       0.61      0.59      0.60      1066\n",
            "weighted avg       0.80      0.80      0.80      1066\n",
            "\n",
            "\n",
            "Done with model 1\n",
            "model no 2, training\n",
            "model name XGBClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.99      0.89       836\n",
            "           1       0.28      0.06      0.10       117\n",
            "           2       0.75      0.19      0.30       113\n",
            "\n",
            "    accuracy                           0.80      1066\n",
            "   macro avg       0.61      0.41      0.43      1066\n",
            "weighted avg       0.75      0.80      0.74      1066\n",
            "\n",
            "\n",
            "Done with model 2\n",
            "model no 3, training\n",
            "model name MLPClassifier\n",
            "Iteration 1, loss = 1.00409274\n",
            "Iteration 2, loss = 0.81241441\n",
            "Iteration 3, loss = 0.66331313\n",
            "Iteration 4, loss = 0.57459870\n",
            "Iteration 5, loss = 0.49135897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.88       836\n",
            "           1       1.00      0.01      0.02       117\n",
            "           2       0.75      0.05      0.10       113\n",
            "\n",
            "    accuracy                           0.79      1066\n",
            "   macro avg       0.85      0.35      0.33      1066\n",
            "weighted avg       0.81      0.79      0.70      1066\n",
            "\n",
            "\n",
            "Done with model 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBQrZUyW-FQ3",
        "outputId": "c3da1d20-747d-4c40-dff5-3875982238ed"
      },
      "source": [
        "task_2_map ={\n",
        "    'NGEN' : 0,\n",
        "    'GEN' : 1,\n",
        "}\n",
        "v1 = feature_extraction.text.CountVectorizer()\n",
        "v2 = feature_extraction.text.TfidfVectorizer()\n",
        "\n",
        "train_clean = get_clean_dataset(train, True,'B','A', task_2_map, vectorizer=v2)\n",
        "val_clean = get_clean_dataset(val, False, 'B', 'A', task_2_map, vectorizer=v2)\n",
        "\n",
        "# print(train_clean[1][1:10])\n",
        "s_2 = np.bincount(train_clean[1])\n",
        "# print(s_2)\n",
        "\n",
        "weights_2 = {i : s_2.sum() / s_2[i] for i in range(2)}\n",
        "w = s_2[0]/s_2[1]\n",
        "\n",
        "model1 = ensemble.RandomForestClassifier(class_weight=weights_2, random_state=0, criterion='entropy')\n",
        "model2 = svm.LinearSVC(class_weight=weights_2, random_state=0)\n",
        "model3 = xgboost.XGBClassifier(scale_pos_weight=w, random_state=0)\n",
        "model4 = neural_network.MLPClassifier(random_state=0, verbose=True, learning_rate='adaptive',max_iter=5 )\n",
        "\n",
        "model_list = [model1, model2, model3, model4]\n",
        "\n",
        "print(f\"Vectorizer used : {type(v2).__name__}\", end=\"\\n\\n\")\n",
        "\n",
        "for i, model in enumerate(model_list):\n",
        "  print(f\"model no {i}, training\")\n",
        "  print(f\"model name {type(model).__name__}\")\n",
        "  preds = model.fit(train_clean[0], train_clean[1]).predict(val_clean[0])\n",
        "  true_preds = val_clean[1]\n",
        "  print(metrics.classification_report(true_preds, preds))\n",
        "  print(f\"\\nDone with model {i}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizer used : TfidfVectorizer\n",
            "\n",
            "model no 0, training\n",
            "model name RandomForestClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96       993\n",
            "           1       0.20      0.01      0.03        73\n",
            "\n",
            "    accuracy                           0.93      1066\n",
            "   macro avg       0.57      0.50      0.49      1066\n",
            "weighted avg       0.88      0.93      0.90      1066\n",
            "\n",
            "\n",
            "Done with model 0\n",
            "model no 1, training\n",
            "model name LinearSVC\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96       993\n",
            "           1       0.52      0.44      0.47        73\n",
            "\n",
            "    accuracy                           0.93      1066\n",
            "   macro avg       0.74      0.70      0.72      1066\n",
            "weighted avg       0.93      0.93      0.93      1066\n",
            "\n",
            "\n",
            "Done with model 1\n",
            "model no 2, training\n",
            "model name XGBClassifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93       993\n",
            "           1       0.31      0.59      0.41        73\n",
            "\n",
            "    accuracy                           0.88      1066\n",
            "   macro avg       0.64      0.75      0.67      1066\n",
            "weighted avg       0.92      0.88      0.90      1066\n",
            "\n",
            "\n",
            "Done with model 2\n",
            "model no 3, training\n",
            "model name MLPClassifier\n",
            "Iteration 1, loss = 0.62576700\n",
            "Iteration 2, loss = 0.45205226\n",
            "Iteration 3, loss = 0.32783910\n",
            "Iteration 4, loss = 0.26395173\n",
            "Iteration 5, loss = 0.22744643\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96       993\n",
            "           1       0.00      0.00      0.00        73\n",
            "\n",
            "    accuracy                           0.93      1066\n",
            "   macro avg       0.47      0.50      0.48      1066\n",
            "weighted avg       0.87      0.93      0.90      1066\n",
            "\n",
            "\n",
            "Done with model 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u0BjCRaDDLk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}